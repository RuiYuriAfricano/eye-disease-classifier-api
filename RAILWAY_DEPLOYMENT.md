# ğŸš€ Guia de Deploy no Railway - VersÃµes DisponÃ­veis

## ğŸ›¡ï¸ Problema Resolvido: Crashes no Carregamento do Modelo

O modelo de 169MB estava causando crashes no Railway devido a problemas com CUDA/GPU. Implementamos **duas versÃµes** para resolver isso:

## ğŸ“‹ VersÃµes DisponÃ­veis

### 1. ğŸ”§ **VersÃ£o Principal (api/main.py)** - Melhorada
- âœ… ConfiguraÃ§Ãµes otimizadas do TensorFlow
- ğŸ”„ Sistema de retry automÃ¡tico
- ğŸ’¾ Monitoramento de memÃ³ria
- ğŸ” VerificaÃ§Ã£o de integridade do modelo
- ğŸ› ï¸ Endpoints de gerenciamento (`/reload-model`, `/memory`)

### 2. ğŸ›¡ï¸ **VersÃ£o CPU-Only (api/main_cpu_only.py)** - Ultra-Segura
- ğŸš« **FORÃ‡A uso apenas de CPU** (sem GPU/CUDA)
- âš¡ Carregamento ultra-conservador
- ğŸ§¹ Preprocessamento simplificado
- ğŸ“¦ CompilaÃ§Ã£o manual do modelo
- ğŸ¯ **Recomendada para Railway**

## ğŸ”„ Como Alternar Entre VersÃµes

### OpÃ§Ã£o 1: Usar VersÃ£o CPU-Only (Recomendado)

Altere o `railway.toml`:
```toml
[deploy]
startCommand = "uvicorn api.main_cpu_only:app --host 0.0.0.0 --port $PORT"
```

Ou use o script:
```toml
[deploy]
startCommand = "python run_api_cpu_only.py"
```

### OpÃ§Ã£o 2: Usar VersÃ£o Principal Melhorada

```toml
[deploy]
startCommand = "uvicorn api.main:app --host 0.0.0.0 --port $PORT"
```

## ğŸ› ï¸ ConfiguraÃ§Ãµes Aplicadas na VersÃ£o CPU-Only

```bash
CUDA_VISIBLE_DEVICES=-1          # Desabilitar GPU completamente
TF_CPP_MIN_LOG_LEVEL=3          # Suprimir logs TensorFlow
TF_FORCE_GPU_ALLOW_GROWTH=false # Desabilitar crescimento GPU
TF_ENABLE_ONEDNN_OPTS=0         # Desabilitar otimizaÃ§Ãµes OneDNN
TF_DISABLE_MKL=1                # Desabilitar MKL
TF_NUM_INTEROP_THREADS=1        # Limitar threads
TF_NUM_INTRAOP_THREADS=1        # Limitar threads
OMP_NUM_THREADS=1               # Limitar OpenMP
```

## ğŸ“Š Endpoints de Monitoramento

Ambas as versÃµes incluem:

- `GET /health` - Status da API e modelo
- `GET /status` - Status detalhado (sÃ³ versÃ£o principal)
- `GET /memory` - Uso de memÃ³ria (sÃ³ versÃ£o principal)
- `POST /reload-model` - ForÃ§ar recarregamento

## ğŸ” Como Monitorar no Railway

1. **Logs em Tempo Real**: Acompanhe o carregamento do modelo
2. **Health Check**: Acesse `/health` para ver o status
3. **MemÃ³ria**: Use `/memory` para monitorar uso de recursos

## ğŸ¯ Logs Esperados (VersÃ£o CPU-Only)

```
ğŸš€ Iniciando API CPU-only...
ğŸ’¾ MemÃ³ria inicial: 66.64MB
ğŸ”„ Iniciando carregamento ultra-seguro...
ğŸ”§ Configurando TensorFlow...
ğŸ–¥ï¸ GPUs fÃ­sicas detectadas: 0
ğŸ–¥ï¸ GPUs visÃ­veis (deve ser 0): 0
âœ… TensorFlow configurado para CPU APENAS
ğŸ“¦ Importando TensorFlow/Keras...
ğŸ”„ Carregando modelo (CPU apenas)...
ğŸ”§ Compilando modelo...
âœ… Modelo compilado com sucesso
ğŸ§ª Testando modelo...
ğŸ’¾ MemÃ³ria final: 650.2MB
ğŸ“ˆ Incremento: 583.6MB
ğŸ‰ Modelo carregado com sucesso!
```

## âš ï¸ Troubleshooting

### Se ainda crashar:
1. Verifique se estÃ¡ usando `api.main_cpu_only:app`
2. Aumente o `healthcheckTimeout` para 900s
3. Monitore os logs para identificar onde para

### Se o modelo nÃ£o carregar:
1. Use `POST /reload-model` para tentar novamente
2. Verifique `/health` para ver erros
3. A API funcionarÃ¡ em modo demo atÃ© o modelo carregar

## ğŸš€ Deploy Atual

As alteraÃ§Ãµes jÃ¡ foram enviadas para o GitHub. O Railway detectarÃ¡ automaticamente e farÃ¡ o redeploy.

**ConfiguraÃ§Ã£o atual no railway.toml:**
- âœ… Timeout aumentado para 900s
- âœ… Comando otimizado
- âœ… Health check configurado

## ğŸ“ PrÃ³ximos Passos

1. **Aguarde o redeploy** do Railway
2. **Monitore os logs** para ver o carregamento
3. **Teste os endpoints** `/health` e `/predict`
4. **Se necessÃ¡rio**, use `/reload-model` para forÃ§ar recarregamento

A versÃ£o CPU-only deve resolver definitivamente os crashes! ğŸ‰
