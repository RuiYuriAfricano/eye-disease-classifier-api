"""
Vers√£o ultra-conservadora da API que for√ßa uso apenas de CPU
e carrega o modelo de forma extremamente segura
"""

import os
import sys

# CONFIGURA√á√ïES CR√çTICAS - DEVE SER A PRIMEIRA COISA
os.environ['CUDA_VISIBLE_DEVICES'] = '-1'  # Desabilitar CUDA completamente
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Suprimir logs TensorFlow
os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'false'
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'
os.environ['TF_DISABLE_MKL'] = '1'
os.environ['TF_NUM_INTEROP_THREADS'] = '1'
os.environ['TF_NUM_INTRAOP_THREADS'] = '1'
os.environ['OMP_NUM_THREADS'] = '1'
os.environ['OPENBLAS_NUM_THREADS'] = '1'
os.environ['MKL_NUM_THREADS'] = '1'
os.environ['VECLIB_MAXIMUM_THREADS'] = '1'
os.environ['NUMEXPR_NUM_THREADS'] = '1'

from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from PIL import Image
import numpy as np
import gdown
import io
import uvicorn
from typing import Dict, List
import logging
import threading
import time
import gc
import psutil

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Configura√ß√µes do modelo
MODEL_PATH = "best_model.keras"
MODEL_URL = "https://drive.google.com/uc?id=1vSIfD3viT5JSxpG4asA8APCwK0JK9Dvu"
CLASS_NAMES = ['cataract', 'diabetic_retinopathy', 'glaucoma', 'normal']

# Vari√°veis globais
model = None
model_loading = False
model_load_error = None

app = FastAPI(
    title="Eye Disease Classifier API - CPU Only",
    description="API para classifica√ß√£o de doen√ßas oculares (CPU apenas)",
    version="1.0.0"
)

# Configurar CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

def get_memory_usage():
    """Retorna uso de mem√≥ria"""
    try:
        process = psutil.Process(os.getpid())
        memory_info = process.memory_info()
        return {
            "rss_mb": round(memory_info.rss / 1024 / 1024, 2),
            "percent": round(process.memory_percent(), 2)
        }
    except:
        return {"rss_mb": 0, "percent": 0}

def download_model_if_needed():
    """Baixa o modelo se necess√°rio"""
    if os.path.exists(MODEL_PATH):
        file_size = os.path.getsize(MODEL_PATH)
        if file_size > 100_000_000:  # Pelo menos 100MB
            logger.info(f"‚úÖ Modelo j√° existe: {file_size / 1_000_000:.1f}MB")
            return True
    
    logger.info("üîΩ Baixando modelo...")
    try:
        gdown.download(MODEL_URL, MODEL_PATH, quiet=False, fuzzy=True)
        if os.path.exists(MODEL_PATH):
            file_size = os.path.getsize(MODEL_PATH)
            logger.info(f"‚úÖ Modelo baixado: {file_size / 1_000_000:.1f}MB")
            return True
    except Exception as e:
        logger.error(f"‚ùå Erro no download: {e}")
    
    return False

def load_model_ultra_safe():
    """Carrega modelo de forma ultra-segura"""
    global model, model_loading, model_load_error
    
    if model_loading:
        return
    
    model_loading = True
    
    try:
        logger.info("üîÑ Iniciando carregamento ultra-seguro...")
        
        # Verificar mem√≥ria inicial
        memory_before = get_memory_usage()
        logger.info(f"üíæ Mem√≥ria inicial: {memory_before['rss_mb']}MB")
        
        # Baixar modelo se necess√°rio
        if not download_model_if_needed():
            raise Exception("Falha no download do modelo")
        
        # Configurar TensorFlow de forma ultra-conservadora
        logger.info("üîß Configurando TensorFlow...")
        import tensorflow as tf
        
        # For√ßar CPU apenas
        tf.config.set_visible_devices([], 'GPU')
        tf.config.threading.set_intra_op_parallelism_threads(1)
        tf.config.threading.set_inter_op_parallelism_threads(1)
        
        logger.info("üì¶ Importando Keras...")
        from keras.models import load_model
        
        # Carregar modelo
        logger.info("üîÑ Carregando modelo (CPU apenas)...")
        model = load_model(MODEL_PATH, compile=False)
        
        # Compilar de forma segura
        logger.info("üîß Compilando modelo...")
        model.compile(
            optimizer='adam',
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )
        
        # Teste simples
        logger.info("üß™ Testando modelo...")
        test_input = np.random.random((1, 256, 256, 3)).astype(np.float32)
        _ = model.predict(test_input, verbose=0)
        
        # Verificar mem√≥ria final
        memory_after = get_memory_usage()
        logger.info(f"üíæ Mem√≥ria final: {memory_after['rss_mb']}MB")
        logger.info(f"üìà Incremento: {memory_after['rss_mb'] - memory_before['rss_mb']:.1f}MB")
        
        logger.info("üéâ Modelo carregado com sucesso!")
        model_load_error = None
        
    except Exception as e:
        error_msg = f"Erro no carregamento: {str(e)}"
        logger.error(f"‚ùå {error_msg}")
        model_load_error = error_msg
        model = "demo_mode"
        
        # Limpeza de mem√≥ria
        gc.collect()
        
    finally:
        model_loading = False

@app.on_event("startup")
async def startup_event():
    """Inicializa√ß√£o da API"""
    logger.info("üöÄ Iniciando API CPU-Only...")
    
    memory_info = get_memory_usage()
    logger.info(f"üíæ Mem√≥ria inicial: {memory_info['rss_mb']}MB")
    
    # Carregar modelo em background
    def load_background():
        time.sleep(2)  # Aguardar API inicializar
        load_model_ultra_safe()
    
    thread = threading.Thread(target=load_background, daemon=True)
    thread.start()
    
    logger.info("‚úÖ API iniciada!")

@app.get("/")
async def root():
    """Endpoint raiz"""
    return {
        "message": "Eye Disease Classifier API - CPU Only",
        "version": "1.0.0",
        "status": "running",
        "model_loaded": model is not None and model != "demo_mode",
        "classes": CLASS_NAMES,
        "timestamp": time.time()
    }

@app.get("/ping")
async def ping():
    """Endpoint simples para verificar se a API est√° respondendo"""
    return {"status": "ok", "message": "pong", "timestamp": time.time()}

@app.get("/health")
async def health_check():
    """Health check - sempre retorna healthy para Railway"""
    global model, model_loading, model_load_error

    memory_info = get_memory_usage()

    # SEMPRE retornar status healthy para passar no health check do Railway
    base_response = {
        "status": "healthy",
        "memory_usage": memory_info,
        "timestamp": time.time()
    }

    if model is None:
        if model_loading:
            return {
                **base_response,
                "message": "API saud√°vel - modelo sendo carregado",
                "model_loaded": False,
                "loading": True
            }
        else:
            return {
                **base_response,
                "message": "API saud√°vel - aguardando carregamento do modelo",
                "model_loaded": False,
                "error": model_load_error
            }
    elif model == "demo_mode":
        return {
            **base_response,
            "message": "API saud√°vel - funcionando em modo demo",
            "model_loaded": False,
            "demo_mode": True,
            "error": model_load_error
        }
    else:
        return {
            **base_response,
            "message": "API saud√°vel - modelo carregado com sucesso",
            "model_loaded": True
        }

def preprocess_image(image: Image.Image) -> np.ndarray:
    """Preprocessa imagem"""
    if image.mode != 'RGB':
        image = image.convert('RGB')
    
    image = image.resize((256, 256))
    img_array = np.array(image)
    
    # Preprocessamento simples (sem inception_v3 para evitar problemas)
    img_array = img_array.astype(np.float32) / 255.0
    img_array = (img_array - 0.5) * 2.0  # Normalizar para [-1, 1]
    img_array = np.expand_dims(img_array, axis=0)
    
    return img_array

@app.post("/predict")
async def predict_disease(file: UploadFile = File(...)) -> Dict:
    """Predi√ß√£o de doen√ßas"""
    if model is None:
        raise HTTPException(status_code=500, detail="Modelo n√£o carregado")
    
    if file.content_type not in ["image/jpeg", "image/jpg", "image/png"]:
        raise HTTPException(status_code=400, detail="Tipo de arquivo n√£o suportado")
    
    try:
        # Ler imagem
        image_data = await file.read()
        image = Image.open(io.BytesIO(image_data))
        
        # Modo demo
        if model == "demo_mode":
            import random
            random.seed(hash(str(image_data)) % 1000)
            
            probs = [random.uniform(0.1, 0.9) for _ in CLASS_NAMES]
            total = sum(probs)
            probs = [p/total for p in probs]
            
            predicted_class_idx = probs.index(max(probs))
            predicted_class = CLASS_NAMES[predicted_class_idx]
            confidence = max(probs)
            
            all_predictions = {
                class_name: float(prob)
                for class_name, prob in zip(CLASS_NAMES, probs)
            }
            
            return {
                "predicted_class": predicted_class,
                "confidence": confidence,
                "all_predictions": all_predictions,
                "status": "demo_mode",
                "message": "Predi√ß√£o simulada"
            }
        
        # Predi√ß√£o real
        processed_image = preprocess_image(image)
        prediction = model.predict(processed_image, verbose=0)[0]
        
        predicted_class_idx = np.argmax(prediction)
        predicted_class = CLASS_NAMES[predicted_class_idx]
        confidence = float(np.max(prediction))
        
        all_predictions = {
            class_name: float(prob)
            for class_name, prob in zip(CLASS_NAMES, prediction)
        }
        
        return {
            "predicted_class": predicted_class,
            "confidence": confidence,
            "all_predictions": all_predictions,
            "status": "success"
        }
        
    except Exception as e:
        logger.error(f"Erro na predi√ß√£o: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Erro na predi√ß√£o: {str(e)}")

@app.get("/classes")
async def get_classes() -> Dict[str, List[str]]:
    """Classes dispon√≠veis"""
    return {"classes": CLASS_NAMES}

@app.post("/reload-model")
async def reload_model():
    """For√ßa recarregamento"""
    global model, model_load_error
    
    if model_loading:
        return {"status": "error", "message": "Carregamento em andamento"}
    
    model = None
    model_load_error = None
    
    def reload_background():
        load_model_ultra_safe()
    
    thread = threading.Thread(target=reload_background, daemon=True)
    thread.start()
    
    return {"status": "success", "message": "Recarregamento iniciado"}

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)
